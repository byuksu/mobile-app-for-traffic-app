{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jx3CnJlXH0AO"
      },
      "outputs": [],
      "source": [
        "!pip install pyrebase4\n",
        "!pip install firebase_admin\n",
        "!pip install supervision\n",
        "!pip install ultralytics\n",
        "!pip install easyocr\n",
        "!pip install dill"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ultralytics\n",
        "import supervision as sv\n",
        "from ultralytics import YOLO\n",
        "\n",
        "ultralytics.checks()\n",
        "model = YOLO(\"yolov8x.pt\")\n",
        "model.fuse()\n",
        "\n",
        "\n",
        "# dict maping class_id to class_name\n",
        "CLASS_NAMES_DICT = model.model.names\n",
        "\n",
        "# class_ids of interest - car, motorcycle, bus and truck\n",
        "selected_classes = [2, 3, 5, 7]\n",
        "filtered_classes = [9]\n",
        "\n",
        "# felipe util codes\n",
        "import string\n",
        "import easyocr\n",
        "\n",
        "# Initialize the OCR reader\n",
        "reader = easyocr.Reader(['en'], gpu=True)\n",
        "\n",
        "# Mapping dictionaries for character conversion\n",
        "dict_char_to_int = {'O': '0',\n",
        "                    'I': '1',\n",
        "                    'J': '3',\n",
        "                    'A': '4',\n",
        "                    'G': '6',\n",
        "                    'S': '5'}\n",
        "\n",
        "dict_int_to_char = {'0': 'O',\n",
        "                    '1': 'I',\n",
        "                    '3': 'J',\n",
        "                    '4': 'A',\n",
        "                    '6': 'G',\n",
        "                    '5': 'S'}\n",
        "\n",
        "# felipe util codes\n",
        "import string\n",
        "import easyocr\n",
        "\n",
        "# Initialize the OCR reader\n",
        "reader = easyocr.Reader(['en'], gpu=True)\n",
        "\n",
        "# Mapping dictionaries for character conversion\n",
        "dict_char_to_int = {'O': '0',\n",
        "                    'I': '1',\n",
        "                    'J': '3',\n",
        "                    'A': '4',\n",
        "                    'G': '6',\n",
        "                    'S': '5'}\n",
        "\n",
        "dict_int_to_char = {'0': 'O',\n",
        "                    '1': 'I',\n",
        "                    '3': 'J',\n",
        "                    '4': 'A',\n",
        "                    '6': 'G',\n",
        "                    '5': 'S'}\n",
        "\n",
        "def write_csv(results, output_path):\n",
        "    with open(output_path, 'w') as f:\n",
        "        f.write('{},{},{},{},{},{},{}\\n'.format('frame_nmr', 'car_id', 'car_bbox',\n",
        "                                                'license_plate_bbox', 'license_plate_bbox_score', 'license_number',\n",
        "                                                'license_number_score'))\n",
        "\n",
        "        for frame_nmr in results.keys():# print(results.keys()) gives dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]). print(frame_nmr) gives elements of the previous one.\n",
        "            for car_id in results[frame_nmr].keys():# type of both the frame_nmr and car_id is a number\n",
        "                #print(results[frame_nmr][car_id])\n",
        "                f.write('{},{},{},{},{},{},{}\\n'.format(frame_nmr,car_id,\n",
        "                                                            '[{} {} {} {}]'.format(\n",
        "                                                                results[frame_nmr][car_id]['car']['bbox'][0],\n",
        "                                                                results[frame_nmr][car_id]['car']['bbox'][1],\n",
        "                                                                results[frame_nmr][car_id]['car']['bbox'][2],\n",
        "                                                                results[frame_nmr][car_id]['car']['bbox'][3]),\n",
        "                                                            '[{} {} {} {}]'.format(\n",
        "                                                                results[frame_nmr][car_id]['license_plate']['bbox'][0],\n",
        "                                                                results[frame_nmr][car_id]['license_plate']['bbox'][1],\n",
        "                                                                results[frame_nmr][car_id]['license_plate']['bbox'][2],\n",
        "                                                                results[frame_nmr][car_id]['license_plate']['bbox'][3]),\n",
        "                                                            results[frame_nmr][car_id]['license_plate']['bbox_score'],\n",
        "                                                            results[frame_nmr][car_id]['license_plate']['text'],\n",
        "                                                            results[frame_nmr][car_id]['license_plate']['text_score'])\n",
        "                        )\n",
        "        f.close()\n",
        "\n",
        "\n",
        "def license_complies_format(text):\n",
        "    \"\"\"\n",
        "    Check if the license plate text complies with the required format.\n",
        "\n",
        "    Args:\n",
        "        text (str): License plate text.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if the license plate complies with the format, False otherwise.\n",
        "    \"\"\"\n",
        "\n",
        "    if len(text) != 7:\n",
        "        return False\n",
        "\n",
        "    if (text[0] in string.ascii_uppercase or text[0] in dict_int_to_char.keys()) and \\\n",
        "       (text[1] in string.ascii_uppercase or text[1] in dict_int_to_char.keys()) and \\\n",
        "       (text[2] in ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'] or text[2] in dict_char_to_int.keys()) and \\\n",
        "       (text[3] in ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'] or text[3] in dict_char_to_int.keys()) and \\\n",
        "       (text[4] in string.ascii_uppercase or text[4] in dict_int_to_char.keys()) and \\\n",
        "       (text[5] in string.ascii_uppercase or text[5] in dict_int_to_char.keys()) and \\\n",
        "       (text[6] in string.ascii_uppercase or text[6] in dict_int_to_char.keys()):\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "\n",
        "def format_license(text):\n",
        "    \"\"\"\n",
        "    Format the license plate text by converting characters using the mapping dictionaries.\n",
        "\n",
        "    Args:\n",
        "        text (str): License plate text.\n",
        "\n",
        "    Returns:\n",
        "        str: Formatted license plate text.\n",
        "    \"\"\"\n",
        "    license_plate_ = ''\n",
        "    mapping = {0: dict_int_to_char, 1: dict_int_to_char, 4: dict_int_to_char, 5: dict_int_to_char, 6: dict_int_to_char,\n",
        "               2: dict_char_to_int, 3: dict_char_to_int}\n",
        "    for j in [0, 1, 2, 3, 4, 5, 6]:\n",
        "        if text[j] in mapping[j].keys():\n",
        "            license_plate_ += mapping[j][text[j]]\n",
        "        else:\n",
        "            license_plate_ += text[j]\n",
        "\n",
        "    return license_plate_\n",
        "\n",
        "\n",
        "def read_license_plate(license_plate_crop):\n",
        "    detections = reader.readtext(license_plate_crop)\n",
        "\n",
        "    for detection in detections:\n",
        "        bbox, text, score = detection\n",
        "\n",
        "        text = text.upper().replace(' ', '')\n",
        "\n",
        "        return text, score\n",
        "\n",
        "    return None, None\n",
        "\n",
        "\n",
        "\n",
        "def get_car(license_plate, vehicle_track_ids):\n",
        "    \"\"\"\n",
        "    Retrieve the vehicle coordinates and ID based on the license plate coordinates.\n",
        "\n",
        "    Args:\n",
        "        license_plate (tuple): Tuple containing the coordinates of the license plate (x1, y1, x2, y2, score, class_id).\n",
        "        vehicle_track_ids (list): List of vehicle track IDs and their corresponding coordinates.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Tuple containing the vehicle coordinates (x1, y1, x2, y2) and ID.\n",
        "    \"\"\"\n",
        "    x1, y1, x2, y2, score, class_id = license_plate\n",
        "\n",
        "    foundIt = False\n",
        "    for j in range(len(vehicle_track_ids)):\n",
        "        xcar1, ycar1, xcar2, ycar2, car_id = vehicle_track_ids[j]\n",
        "\n",
        "        if x1 > xcar1 and y1 > ycar1 and x2 < xcar2 and y2 < ycar2:\n",
        "            car_indx = j\n",
        "            foundIt = True\n",
        "            break\n",
        "\n",
        "    if foundIt:\n",
        "        return vehicle_track_ids[car_indx]\n",
        "\n",
        "    return -1, -1, -1, -1, -1\n",
        "\n",
        "#preprocess functions\n",
        "\"\"\"\n",
        "I can get rid of cv2.imshow functions. They exist due to debugging purposes.\n",
        "\n",
        "Second preprocess function works better on resized images.\n",
        "First one works better on original crop but reader cannot read it\n",
        "\n",
        "Now I will try to erase blue part from license plates.\n",
        "\n",
        "!!! due to enhance_quality function, I no more read plaka0.png. I need to remove it.\n",
        "\"\"\"\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def preprocess(image):\n",
        "    resized = resize_maintain_aspect(image,300)\n",
        "    #better = enhance_quality(resized)\n",
        "    #blueless = remove_blue(resized)\n",
        "    processed_blueless = process_image_second_way(resized)\n",
        "    #processed_blueless = process_image(resized)\n",
        "    return processed_blueless\n",
        "\n",
        "def process_image(image):\n",
        "    # Convert the image to grayscale\n",
        "    #cv2.imshow('original Image1', image)\n",
        "    #cv2.waitKey(0)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    #cv2.imshow('gray Image1', gray)\n",
        "    #cv2.waitKey(0)\n",
        "    # Apply Gaussian blur to reduce noise\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    #cv2.imshow('blur Image1', blurred)\n",
        "    #cv2.waitKey(0)\n",
        "    # thresh image contains distorsions due to shadows. I need to eliminate that.\n",
        "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 4)\n",
        "    #cv2.imshow('thresh Image1', thresh)\n",
        "    #cv2.waitKey(0)\n",
        "    # Invert the colors (black background, white foreground)\n",
        "    processed_image = cv2.bitwise_not(thresh)\n",
        "    #cv2.imshow('processed Image1', processed_image)\n",
        "    #cv2.waitKey(0)\n",
        "    return processed_image\n",
        "\n",
        "def process_image_second_way(image):\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    #cv2.imshow('gray Image', gray)\n",
        "    #cv2.waitKey(0)\n",
        "    # Apply Gaussian blur to reduce noise\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    #cv2.imshow('blur Image', blurred)\n",
        "    #cv2.waitKey(0)\n",
        "    # Apply Otsu's thresholding to binarize the image\n",
        "    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "    #cv2.imshow('thresh Image', thresh)\n",
        "    #cv2.waitKey(0)\n",
        "    # Perform morphological operations to remove noise and smooth the image\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
        "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
        "\n",
        "    # Invert the colors (black background, white foreground)\n",
        "    processed_image_second = cv2.bitwise_not(closing)\n",
        "    #cv2.imshow('processed Image', processed_image_second)\n",
        "    #cv2.waitKey(0)\n",
        "    return processed_image_second\n",
        "\n",
        "\n",
        "def remove_blue(image):\n",
        "    # Convert image from BGR to HSV color space\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "    #cv2.imshow('hsv Image', hsv)\n",
        "    #cv2.waitKey(0)\n",
        "    # Define lower and upper bounds for blue color in HSV\n",
        "    lower_blue = np.array([90, 50, 50])\n",
        "    upper_blue = np.array([130, 255, 255])\n",
        "\n",
        "    # Create a binary mask of blue regions\n",
        "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
        "    #cv2.imshow('mask Image', mask)\n",
        "    #cv2.waitKey(0)\n",
        "    # Invert the mask (blue regions become black, non-blue regions become white)\n",
        "    mask = cv2.bitwise_not(mask)\n",
        "    #cv2.imshow('mask bitwise_not Image', mask)\n",
        "    #cv2.waitKey(0)\n",
        "    # Apply the mask to the original image to remove blue regions\n",
        "    result = cv2.bitwise_and(image, image, mask=mask)\n",
        "    #cv2.imshow('result Image', result)\n",
        "    #cv2.waitKey(0)\n",
        "\n",
        "    return result\n",
        "\n",
        "def resize_maintain_aspect(image, new_width=None, new_height=None):\n",
        "    # Get the original image dimensions\n",
        "    (h, w) = image.shape[:2]\n",
        "\n",
        "    if new_width is None and new_height is None:\n",
        "        return image\n",
        "\n",
        "    if new_width is None:\n",
        "        # Calculate the ratio of the new height to the original height\n",
        "        ratio = new_height / float(h)\n",
        "        # Resize the image using the ratio\n",
        "        dim = (int(w * ratio), new_height)\n",
        "    else:\n",
        "        # Calculate the ratio of the new width to the original width\n",
        "        ratio = new_width / float(w)\n",
        "        # Resize the image using the ratio\n",
        "        dim = (new_width, int(h * ratio))\n",
        "\n",
        "    # Resize the image while maintaining its aspect ratio\n",
        "    resized = cv2.resize(image, dim, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    return resized\n",
        "\n",
        "def enhance_quality(image):\n",
        "    # Apply unsharp masking for sharpening\n",
        "    blurred = cv2.GaussianBlur(image, (0, 0), 3)\n",
        "    cv2.imshow('blurred Image', blurred)\n",
        "    cv2.waitKey(0)\n",
        "    sharpened = cv2.addWeighted(image, 1.5, blurred, -0.5, 0)\n",
        "    cv2.imshow('sharpenned Image', sharpened)\n",
        "    cv2.waitKey(0)\n",
        "\n",
        "    # Apply histogram equalization for contrast enhancement\n",
        "    gray = cv2.cvtColor(sharpened, cv2.COLOR_BGR2GRAY)\n",
        "    equalized = cv2.equalizeHist(gray)\n",
        "    cv2.imshow('equalized Image', equalized)\n",
        "    cv2.waitKey(0)\n",
        "    enhanced = cv2.merge([equalized, equalized, equalized])\n",
        "    cv2.imshow('enhanced Image', enhanced)\n",
        "    cv2.waitKey(0)\n",
        "\n",
        "    return enhanced\n",
        "\n",
        "# this function checks whether the plate has a correct form or not.\n",
        "proper_characters = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"R\",\"S\",\"T\",\"U\",\"V\",\"Y\",\"Z\"]\n",
        "proper_numbers = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]\n",
        "proper = proper_characters + proper_numbers\n",
        "\n",
        "def proper_license_plate_check(text):\n",
        "  if len(text)<7 or len(text)>8:\n",
        "    #print(\"here1\")\n",
        "    return False\n",
        "  else:\n",
        "    if text[0] not in proper_numbers:\n",
        "      #print(\"here2\")\n",
        "      return False\n",
        "    elif text[1] not in proper_numbers:\n",
        "      #print(\"here3\")\n",
        "      return False\n",
        "    elif text[2] not in proper_characters:\n",
        "      #print(\"here4\")\n",
        "      return False\n",
        "    elif text[len(text)-1] not in proper_numbers:\n",
        "      #print(\"here5\")\n",
        "      return False\n",
        "    elif text[len(text)-2] not in proper_numbers:\n",
        "      #print(\"here6\")\n",
        "      return False\n",
        "    else:\n",
        "      for element in text:\n",
        "        if element not in proper:\n",
        "          #print(\"here\")\n",
        "          #print(element)\n",
        "          return False\n",
        "\n",
        "      #print(\"heree\")\n",
        "      #print(element)\n",
        "      return True\n",
        "\n",
        "def image_process(SOURCE_VIDEO_PATH, EXCEL_FILE):\n",
        "  from IPython.display import display, HTML\n",
        "  import cv2\n",
        "  from PIL import Image, ImageDraw, ImageFont\n",
        "  from ultralytics import YOLO\n",
        "  import numpy as np\n",
        "  from collections import defaultdict, Counter\n",
        "  from IPython import display\n",
        "  import ultralytics\n",
        "  import supervision\n",
        "  import supervision as sv\n",
        "  from supervision.draw.utils import draw_line\n",
        "  from supervision.geometry.core import Point\n",
        "  from supervision.draw.color import Color  # Assuming 'Color' is used for specifying colors\n",
        "  from openpyxl import Workbook,load_workbook\n",
        "  import openpyxl as openpyxl\n",
        "  import os\n",
        "  import math\n",
        "  np_model = YOLO('/content/drive/MyDrive/traffic_violation_app/models/license_plate_detector.pt')\n",
        "  sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "  source_video_name = os.path.basename(SOURCE_VIDEO_PATH)\n",
        "  mid_video_path = \"/content/drive/MyDrive/traffic_violation_app/midvideos/\" + source_video_name\n",
        "  TARGET_VIDEO_PATH = \"/content/drive/MyDrive/traffic_violation_app/processedData/Result_\" + source_video_name.replace(\".mp4\",\".mov\")\n",
        "\n",
        "\n",
        "\n",
        "  # Open a video file\n",
        "  video_path = SOURCE_VIDEO_PATH\n",
        "  # Finding width and height of video\n",
        "  cap = cv2.VideoCapture(SOURCE_VIDEO_PATH)\n",
        "  width_video = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "  height_video = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "  cap.release()\n",
        "  # Defining overtaking variables\n",
        "\n",
        "  excel_file = EXCEL_FILE\n",
        "  target_excel_path = \"/content/drive/MyDrive/traffic_violation_app/processedData/\" + os.path.basename(excel_file)\n",
        "\n",
        "  global previous_tracker_ids, overtaking_vio_cars\n",
        "  overtaking_vio_cars = []\n",
        "  previous_tracker_ids = []\n",
        "  global centroid_positions\n",
        "  centroid_positions = []\n",
        "  suscarsdup = []\n",
        "  suscars = []\n",
        "  Lvehicles = set()\n",
        "  global frames, vdet1,vdet2,CC\n",
        "  CC = 'D'\n",
        "  frames = 0\n",
        "  vdet1 = 0\n",
        "  vdet2 = 0\n",
        "  #--------------------------------------------------------------\n",
        "  # Defining light detection variables\n",
        "  line_coordinates = []\n",
        "  frame_lights = []\n",
        "  # Define global variables\n",
        "  vehicle_positions = defaultdict(lambda: (np.inf, np.inf))  # Stores last known y-position of each vehicle\n",
        "  tracked_vehicles_below_line = defaultdict(bool)  # Track if vehicles were initially below the line\n",
        "  consecutive_below_line_counts = defaultdict(int)\n",
        "  consecutive_above_line_counts = defaultdict(int)\n",
        "  red_light_violators = set()  # Set to store IDs of vehicles that have violated red light rules\n",
        "  consecutive_frames_threshold=7\n",
        "  prev_tracker_ids = []\n",
        "  global printed_text\n",
        "  global red_vio_id\n",
        "  red_vio_id=[]\n",
        "  printed_text=None\n",
        "  #---------------------------------------------------------------\n",
        "  #speed variables\n",
        "  global vehicle_speed_detail_list\n",
        "  vehicle_speed_detail_list = []\n",
        "  global height\n",
        "  global previous_tracker_ids_speed\n",
        "  previous_tracker_ids_speed = []\n",
        "  cap = cv2.VideoCapture(SOURCE_VIDEO_PATH)\n",
        "  fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "  total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "  height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "  cap.release()\n",
        "\n",
        "  #---------------------------------------------------------------\n",
        "  # defining license plate variables\n",
        "  license_plates_dict = {}\n",
        "  finalized_lisence_plates = {}\n",
        "  global frame_number\n",
        "  frame_number = 0\n",
        "  global np_score_old\n",
        "  np_score_old = 0\n",
        "  #speed\n",
        "#########################################################################\n",
        "  def speed_dict_creator(vehicle_id, vehicle_speed_detail_list, vehicle_type):\n",
        "\n",
        "    vehicle_speed_detail = {\n",
        "      \"vehicle_id\": vehicle_id,\n",
        "      \"vehicle_type\": vehicle_type,\n",
        "      \"first_crossover_time\": \"\",\n",
        "      \"second_crossover_time\": \"\",\n",
        "      \"third_crossover_time\": \"\",\n",
        "      \"fourth_crossover_time\": \"\",\n",
        "      \"vehicle_relative_speed\": 0,\n",
        "      \"speed_detection_time\": 0,\n",
        "      \"vehicle_exact_speed\": 0,\n",
        "      \"speed_violation\": \"False\"\n",
        "    }\n",
        "    vehicle_speed_detail_list.append(vehicle_speed_detail)\n",
        "    return vehicle_speed_detail_list\n",
        "\n",
        "# çizgilerin üzerinden her araba geçtiğinde listeyi güncelle\n",
        "\n",
        "  def crossover(vehicle_speed_detail_list, line_number, crossover_time, vehicle_id):\n",
        "\n",
        "    for vehicle_speed_detail in vehicle_speed_detail_list:\n",
        "\n",
        "      if int(vehicle_speed_detail['vehicle_id']) == vehicle_id:\n",
        "        if line_number == 1:\n",
        "          vehicle_speed_detail[\"first_crossover_time\"] = crossover_time\n",
        "        elif line_number == 2:\n",
        "          vehicle_speed_detail[\"second_crossover_time\"] = crossover_time\n",
        "        elif line_number == 3:\n",
        "          vehicle_speed_detail[\"third_crossover_time\"] = crossover_time\n",
        "        elif line_number == 4:\n",
        "          vehicle_speed_detail[\"fourth_crossover_time\"] = crossover_time\n",
        "    return vehicle_speed_detail_list\n",
        "\n",
        "# görüntü işleme bittiği zaman araç hızını hesapla\n",
        "\n",
        "  def speed_finder(vehicle_speed_detail_list, excel_file):\n",
        "    import openpyxl\n",
        "    import math\n",
        "    for vehicle_speed_detail in vehicle_speed_detail_list:\n",
        "      if vehicle_speed_detail[\"first_crossover_time\"] and vehicle_speed_detail[\"second_crossover_time\"]:\n",
        "        vehicle_speed_detail[\"vehicle_relative_speed\"] = (vehicle_speed_detail[\"second_crossover_time\"] - vehicle_speed_detail[\"first_crossover_time\"]) / 1 # deneme ile bulacağız\n",
        "        vehicle_speed_detail[\"speed_detection_time\"] = (vehicle_speed_detail[\"second_crossover_time\"] + vehicle_speed_detail[\"first_crossover_time\"]) / 2\n",
        "        print(f'{vehicle_speed_detail[\"vehicle_id\"]} speed: {vehicle_speed_detail[\"vehicle_relative_speed\"]}')\n",
        "      elif vehicle_speed_detail[\"third_crossover_time\"] and vehicle_speed_detail[\"fourth_crossover_time\"]:\n",
        "        vehicle_speed_detail[\"vehicle_relative_speed\"] = (vehicle_speed_detail[\"fourth_crossover_time\"] - vehicle_speed_detail[\"third_crossover_time\"]) * 55# deneme ile bulacağız\n",
        "        vehicle_speed_detail[\"speed_detection_time\"] = (vehicle_speed_detail[\"fourth_crossover_time\"] + vehicle_speed_detail[\"third_crossover_time\"]) / 2\n",
        "        print(f'{vehicle_speed_detail[\"vehicle_id\"]} speed: {vehicle_speed_detail[\"vehicle_relative_speed\"]} time: {vehicle_speed_detail[\"speed_detection_time\"]}')\n",
        "      else:\n",
        "        vehicle_speed_detail[\"vehicle_relative_speed\"] = 0\n",
        "        vehicle_speed_detail[\"speed_detection_time\"] = 0\n",
        "\n",
        "      # Load the workbook\n",
        "      workbook = openpyxl.load_workbook(excel_file)\n",
        "\n",
        "      # Select the active worksheet or specify a sheet name\n",
        "      sheet = workbook.active  # or workbook['Sheet1']\n",
        "      row = math.floor(int(vehicle_speed_detail[\"speed_detection_time\"])) + 2\n",
        "      # Read the value from a specific cell\n",
        "      try:\n",
        "        speed_limit = int(sheet[f'B{row}'].value)\n",
        "        observer_speed = int(sheet[f'F{row}'].value)\n",
        "\n",
        "        vehicle_speed_detail[\"vehicle_exact_speed\"] = observer_speed + int(vehicle_speed_detail[\"vehicle_relative_speed\"])\n",
        "\n",
        "        if int(vehicle_speed_detail[\"vehicle_exact_speed\"]) > speed_limit:\n",
        "          vehicle_speed_detail[\"speed_violation\"] = \"True\"\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "    return vehicle_speed_detail_list\n",
        "\n",
        "\n",
        "\n",
        "  def speed_detector(detections, vehicle_speed_detail_list, frame_number):\n",
        "    global previous_tracker_ids_speed, height\n",
        "    video_time = frame_number / fps\n",
        "\n",
        "    new_tracker_ids_speed = set(detections.tracker_id) - set(previous_tracker_ids_speed)\n",
        "    if new_tracker_ids_speed:\n",
        "      for tracker_id in new_tracker_ids_speed:\n",
        "        detection = detections[detections.tracker_id == tracker_id]\n",
        "        vehicle_type = model.model.names[detection.class_id[0]]\n",
        "        vehicle_speed_detail_list = speed_dict_creator(str(tracker_id), vehicle_speed_detail_list, vehicle_type)\n",
        "    # çizgiden geçiş\n",
        "    for tracker_id in detections.tracker_id:\n",
        "      detection = detections[detections.tracker_id == tracker_id]\n",
        "      bbox = detection.xyxy[0]\n",
        "      y_centroid = (bbox[1] + bbox[3]) / 2\n",
        "      if math.ceil(height * (30/35)) -1 <= y_centroid <= math.ceil(height * (30/35)) + 1:\n",
        "          vehicle_speed_detail_list = crossover(vehicle_speed_detail_list, 1, video_time, tracker_id)\n",
        "          print(f\"vehicle {tracker_id} crossed line 1\")\n",
        "      elif math.ceil(height * (28/35)) -1 <= y_centroid <= math.ceil(height * (28/35)) + 1:\n",
        "          vehicle_speed_detail_list = crossover(vehicle_speed_detail_list, 2, video_time, tracker_id)\n",
        "          print(f\"vehicle {tracker_id} crossed line 2\")\n",
        "      elif math.ceil(height * (222/350)) -1 <= y_centroid <= math.ceil(height * (222/350)) + 1:\n",
        "          vehicle_speed_detail_list = crossover(vehicle_speed_detail_list, 3, video_time, tracker_id)\n",
        "          print(f\"vehicle {tracker_id} crossed line 3\")\n",
        "          print(f\"video time: {video_time}\")\n",
        "      elif math.ceil(height * (220/350)) -1 <= y_centroid <= math.ceil(height * (220/350)) + 1:\n",
        "          vehicle_speed_detail_list = crossover(vehicle_speed_detail_list, 4, video_time, tracker_id)\n",
        "          print(f\"vehicle {tracker_id} crossed line 4\")\n",
        "          print(f\"video time: {video_time}\")\n",
        "\n",
        "\n",
        "    if frame_number == total_frames:\n",
        "      vehicle_speed_detail_list = speed_finder(vehicle_speed_detail_list, excel_file)\n",
        "      print(vehicle_speed_detail_list)\n",
        "      print(\"last frame\")\n",
        "\n",
        "    previous_tracker_ids_speed.extend(new_tracker_ids_speed)\n",
        "\n",
        "  def draw_lines(annotated_frame):\n",
        "      global height\n",
        "      # update line counter\n",
        "      start_point = (0, math.ceil(height * (30/35)))  # The x-coordinate is 0 (leftmost), and the y-coordinate is 770\n",
        "      end_point = (annotated_frame.shape[1], math.ceil(height * (30/35)))  # The x-coordinate is the width of the frame, and the y-coordinate is 770\n",
        "\n",
        "      start_point_1 = (0, math.ceil(height * (28/35)))  # The x-coordinate is 0 (leftmost), and the y-coordinate is 770\n",
        "      end_point_1 = (annotated_frame.shape[1], math.ceil(height * (28/35)))  # The x-coordinate is the width of the frame, and the y-coordinate is 770\n",
        "\n",
        "      start_point_2 = (0, math.ceil(height * (222/350)))  # The x-coordinate is 0 (leftmost), and the y-coordinate is 770\n",
        "      end_point_2 = (annotated_frame.shape[1], math.ceil(height * (222/350)))  # The x-coordinate is the width of the frame, and the y-coordinate is 770\n",
        "\n",
        "      start_point_3 = (0, math.ceil(height * (22/35)))  # The x-coordinate is 0 (leftmost), and the y-coordinate is 770\n",
        "      end_point_3 = (annotated_frame.shape[1], math.ceil(height * (22/35)))  # The x-coordinate is the width of the frame, and the y-coordinate is 770\n",
        "      # Define the color of the line in BGR format (here, it's blue)\n",
        "      color = (255, 0, 0)  # Blue color in BGR\n",
        "\n",
        "      # Draw the line on the frame\n",
        "      thickness = 1  # You can adjust the thickness of the line as needed\n",
        "      cv2.line(annotated_frame, start_point, end_point, color, thickness)\n",
        "      cv2.line(annotated_frame, start_point_1, end_point_1, color, thickness)\n",
        "      cv2.line(annotated_frame, start_point_2, end_point_2, color, thickness)\n",
        "      cv2.line(annotated_frame, start_point_3, end_point_3, color, thickness)\n",
        "\n",
        "#########################################################################\n",
        "  # Create BYTETracker instance\n",
        "  byte_tracker = sv.ByteTrack(track_thresh=0.25, track_buffer=30, match_thresh=0.8, frame_rate=30)\n",
        "\n",
        "  # Create VideoInfo instance\n",
        "  video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "\n",
        "  # Create LineZone instance, it is previously called LineCounter class\n",
        "\n",
        "  # Create instance of BoxAnnotator\n",
        "  box_annotator = sv.BoxAnnotator(thickness=1, text_thickness=2, text_scale=1.5)\n",
        "\n",
        "  # Create instance of TraceAnnotator\n",
        "  trace_annotator = sv.TraceAnnotator(thickness=4, trace_length=50)\n",
        "  def plate(frame,detections,annotated_frame):\n",
        "    for tracker_idvey in detections.tracker_id:\n",
        "      detection = detections[detections.tracker_id == tracker_idvey]\n",
        "      bbox = detection.xyxy[0]\n",
        "      roi_car = frame[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])]\n",
        "      license_plates = np_model(roi_car)[0]\n",
        "      for license_plate in license_plates.boxes.data.tolist():\n",
        "        plate_x1, plate_y1, plate_x2, plate_y2, plate_score, _ = license_plate\n",
        "        plate = roi_car[int(plate_y1):int(plate_y2),int(plate_x1):int(plate_x2)]\n",
        "        crop = preprocess(plate)\n",
        "        np_text, np_score = read_license_plate(crop)\n",
        "        license_plates_dict[frame_number] = {tracker_idvey: {'text': np_text, 'score': np_score}}\n",
        "        if np_score is not None:\n",
        "          if proper_license_plate_check(np_text):\n",
        "            finalized_lisence_plates[tracker_idvey] = {'plaka':np_text,'score': np_score}\n",
        "        if plate_score is not None:\n",
        "          annotated_frame = cv2.rectangle(annotated_frame,(int(plate_x1)+int(bbox[0]), int(plate_y1)+int(bbox[1])),(int(plate_x2)+int(bbox[0]), int(plate_y2)+int(bbox[1])),(0,0,0),thickness=cv2.FILLED)\n",
        "\n",
        "        print(\"**frame number: {} tracker id: {}, text: {}, score: {}\".format(frame_number,tracker_idvey,np_text,np_score))\n",
        "    print(license_plates_dict)\n",
        "    print(finalized_lisence_plates)\n",
        "    return finalized_lisence_plates\n",
        "\n",
        "  def overtaking(frame,detections):\n",
        "    global previous_tracker_ids, centroid_positions, frames,vdet1,vdet2,CC\n",
        "    frames = frames + 1\n",
        "\n",
        "    # Check for new vehicles\n",
        "    new_tracker_ids = set(detections.tracker_id) - set(previous_tracker_ids)\n",
        "    if frames > 1:\n",
        "      for tracker_id in new_tracker_ids:\n",
        "        # Extract bounding box for the new vehicle\n",
        "        detection = detections[detections.tracker_id == tracker_id]\n",
        "        bbox = detection.xyxy[0]\n",
        "        # Calculate centroid position\n",
        "        centroid_position = ((bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2)\n",
        "        if centroid_position[0] > 1700/1920*width_video and centroid_position[1] > 800/1080*height_video:\n",
        "            print(f\"Vehicle with track ID{tracker_id} has violated the rule OVERTAKING OUR VEHICLE ON THE RIGHT\")\n",
        "            vdet1 = 1\n",
        "            Lvehicle1 = tracker_id\n",
        "            overtaking_vio_cars.append(tracker_id)\n",
        "        # Store centroid position for further processing if needed\n",
        "        centroid_positions.append((tracker_id, centroid_position))\n",
        "    # Update previous tracker IDs list\n",
        "    previous_tracker_ids.extend(new_tracker_ids)\n",
        "    if len(suscars) > 0:\n",
        "      for i in range (len(suscars)-1):\n",
        "        tracker_id1 = suscars[i][0]\n",
        "        tracker_id2 = suscars[i][1]\n",
        "        detection1 = detections[detections.tracker_id == tracker_id1]\n",
        "        detection2 = detections[detections.tracker_id == tracker_id2]\n",
        "        if len(detection1) != 0 and len(detection2) != 0:\n",
        "          bbox1 = detection1.xyxy[0]\n",
        "          bbox2 = detection2.xyxy[0]\n",
        "          x1 = (bbox1[0] + bbox1[2]) / 2\n",
        "          x2 = (bbox2[0] + bbox2[2]) / 2\n",
        "          y1 = (bbox1[1] + bbox1[3]) / 2\n",
        "          y2 = (bbox2[1] + bbox2[3]) / 2\n",
        "          if bbox2[3] - bbox1[3] < -1:\n",
        "            if 0 < x2 - x1 < 400/1920*width_video and x1 > 800/1920*width_video:\n",
        "              if tracker_id2 not in Lvehicles:\n",
        "                print(f\"Vehicle with track ID {tracker_id2} has violated the rule OVERTAKING ANOTHER VEHICLE ON THE RIGHT\")\n",
        "                Lvehicles.add(tracker_id2)\n",
        "                vdet2 = 1\n",
        "                Lvehicle2 = tracker_id2\n",
        "                overtaking_vio_cars.append(tracker_id2)\n",
        "    for tracker_id1 in set(detections.tracker_id):\n",
        "      for tracker_id2 in set(detections.tracker_id):\n",
        "        if tracker_id1 != tracker_id2:\n",
        "          detection1 = detections[detections.tracker_id == tracker_id1]\n",
        "          detection2 = detections[detections.tracker_id == tracker_id2]\n",
        "          bbox1 = detection1.xyxy[0]\n",
        "          bbox2 = detection2.xyxy[0]\n",
        "          x1 = (bbox1[0] + bbox1[2]) / 2\n",
        "          x2 = (bbox2[0] + bbox2[2]) / 2\n",
        "          y1 = (bbox1[1] + bbox1[3]) / 2\n",
        "          y2 = (bbox2[1] + bbox2[3]) / 2\n",
        "          if 1 < bbox2[3] - bbox1[3] < 10/1080*height_video:\n",
        "            if 0 < x2 - x1 < 400/1920*width_video:\n",
        "              suscarsdup.append([tracker_id1,tracker_id2])\n",
        "    previous_tracker_ids_list = list(previous_tracker_ids)\n",
        "    for sublist in suscarsdup:\n",
        "      if sublist not in suscars:\n",
        "        suscars.append(sublist)\n",
        "\n",
        "  def redlightvio():\n",
        "    ##############################################\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    # Get video properties\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    # Process each frame in the video\n",
        "    for _ in range(frame_count):\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "        img_width, img_height = img.size  # Add this line to get the image width\n",
        "\n",
        "        # Run inference on the image\n",
        "        results = model([np.array(img)])\n",
        "        # Get class names\n",
        "        class_names = results[0].names\n",
        "\n",
        "        # Initialize a list to store line coordinates\n",
        "        line_buffer = []\n",
        "\n",
        "        # Initialize the smallest box height variable for this frame\n",
        "        smallest_box_height = float('inf')  # Set to infinity initially\n",
        "\n",
        "        for result in results:\n",
        "            for (box, conf, cls) in zip(result.boxes.xyxy, result.boxes.conf, result.boxes.cls):\n",
        "              if int(cls) == 9:  # Filter for class 9\n",
        "\n",
        "                # Calculate box height\n",
        "                box_height = box[3] - box[1]\n",
        "\n",
        "                # Update the smallest box height\n",
        "                if box_height < smallest_box_height:\n",
        "                    smallest_box_height = box_height\n",
        "\n",
        "\n",
        "                # Draw a line downward from the center of the box\n",
        "                center_x = (box[0] + box[2]) / 2\n",
        "                center_y = (box[1] + box[3]) / 2\n",
        "\n",
        "                if smallest_box_height != float('inf'):\n",
        "\n",
        "                    distance_downwards = smallest_box_height * 2\n",
        "\n",
        "                line_buffer.append((center_x, center_y + distance_downwards, center_x, center_y + distance_downwards))\n",
        "\n",
        "\n",
        "                lowest_y_line = max(line_buffer, key=lambda line: max(line[1], line[3]))\n",
        "\n",
        "            if len(line_buffer):\n",
        "                x1, y1, x2, y2 = lowest_y_line\n",
        "\n",
        "            else :\n",
        "                x1=None\n",
        "                x2=None\n",
        "                y1=None\n",
        "                y2=None\n",
        "\n",
        "            # Calculate the length of the green line (four-fifths of the screen width)\n",
        "            green_line_length = img_width\n",
        "\n",
        "            # Calculate the left and right coordinates of the green line\n",
        "            left_coordinate = (img_width - green_line_length) / 2\n",
        "            right_coordinate = img_width - left_coordinate\n",
        "            if x1==None and x2==None and y1==None and y2==None:\n",
        "                line_coordinates.append(((None, None ), (None, None)))\n",
        "            else:\n",
        "\n",
        "                y1=y1 + distance_downwards\n",
        "                y1 = y1.item()  # Ensure y1 is a float if it's a tensor\n",
        "                line_coordinates.append(((left_coordinate, y1), (right_coordinate, y1)))\n",
        "\n",
        "\n",
        "\n",
        "    ##############################################\n",
        "    tl_model = YOLO(r'/content/drive/MyDrive/traffic_violation_app/models/best.pt')\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Get video properties\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    # Process each frame in the video\n",
        "    for _ in range(frame_count):\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Convert the frame to PIL Image\n",
        "        img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "        # Get the size of the image\n",
        "        img_width, img_height = img.size  # Add this line to get the image width\n",
        "\n",
        "        # Run inference on the image\n",
        "        results = tl_model([np.array(img)])\n",
        "\n",
        "        # Get class names\n",
        "        class_names = results[0].names\n",
        "\n",
        "        # Initialize a list to store line coordinates\n",
        "        light_buffer = []\n",
        "\n",
        "        # Draw bounding boxes and class names on the image\n",
        "        for result in results:\n",
        "            for (box, conf, cls) in zip(result.boxes.xyxy, result.boxes.conf, result.boxes.cls):\n",
        "\n",
        "                class_name = class_names[int(cls)]\n",
        "\n",
        "                # Append line coordinates to the line buffer\n",
        "                light_buffer.append(class_names[int(cls)])\n",
        "                counted_elements = Counter(light_buffer)\n",
        "                if len(light_buffer):\n",
        "                    most_common_element = counted_elements.most_common(1)[0][0]\n",
        "                else:\n",
        "                    most_common_element= 'none'\n",
        "\n",
        "\n",
        "            counted_elements = Counter(light_buffer)\n",
        "            if len(light_buffer):\n",
        "                most_common_element = counted_elements.most_common(1)[0][0]\n",
        "            else:\n",
        "                most_common_element= 'none'\n",
        "\n",
        "        # Count the occurrences of each element in the list\n",
        "        counted_elements = Counter(light_buffer)\n",
        "        if len(light_buffer):\n",
        "            most_common_element = counted_elements.most_common(1)[0][0]\n",
        "        else:\n",
        "            most_common_element= 'none'\n",
        "        frame_lights.append(most_common_element)\n",
        "\n",
        "    # Release resources\n",
        "    cap.release()\n",
        "\n",
        "\n",
        "  redlightvio()\n",
        "\n",
        " ####################################################################################\n",
        "  def update_vehicle_positions(detections, y_line):\n",
        "    # Check for new vehicles\n",
        "    new_tracker_ids = set(detections.tracker_id)\n",
        "    if frames > 1:\n",
        "      for tracker_id in new_tracker_ids:\n",
        "        # Extract bounding box for the new vehicle\n",
        "        detection = detections[detections.tracker_id == tracker_id]\n",
        "        bbox = detection.xyxy[0]\n",
        "        # Calculate centroid position\n",
        "        bottom_position = (bbox[3])\n",
        "        vehicle_positions[tracker_id] = bottom_position\n",
        "        if y_line is not None:\n",
        "          if bottom_position > y_line:\n",
        "            consecutive_below_line_counts[tracker_id] += 1\n",
        "          else:\n",
        "            consecutive_below_line_counts[tracker_id] = 0\n",
        "          if consecutive_below_line_counts[tracker_id] >= consecutive_frames_threshold:\n",
        "                tracked_vehicles_below_line[tracker_id] = True\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def check_red_light_violations(y_line):\n",
        "    global printed_text\n",
        "    if y_line is not None:\n",
        "      for tracker_id, was_below_line in tracked_vehicles_below_line.items():\n",
        "        if was_below_line and vehicle_positions[tracker_id] < y_line:\n",
        "            if tracker_id not in red_light_violators:\n",
        "              consecutive_above_line_counts[tracker_id] += 1\n",
        "            else:\n",
        "              consecutive_above_line_counts[tracker_id] = 0\n",
        "        if consecutive_above_line_counts[tracker_id] >=consecutive_frames_threshold:\n",
        "          red_light_violators.add(tracker_id)\n",
        "          red_vio_id.append(tracker_id)\n",
        "          tracked_vehicles_below_line[tracker_id] = False\n",
        "  def redlight(frame, current_light_state, y0, detections):\n",
        "    global tracked_vehicles_below_line, vehicle_positions, red_light_violators, consecutive_above_line_counts, consecutive_below_line_counts\n",
        "\n",
        "    # Convert frame to PIL Image for processing\n",
        "    pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "\n",
        "    update_vehicle_positions(detections, y0)\n",
        "\n",
        "    if current_light_state == 'red':\n",
        "      check_red_light_violations(y0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  ######################################################################################\n",
        "  # Define call back function to be used in video processing\n",
        "  def callback(frame: np.ndarray, index:int) -> np.ndarray:\n",
        "    try:\n",
        "\n",
        "      # Extracting the coordinates for the current frame\n",
        "      x0, y0 = line_coordinates[index][0]\n",
        "      x1, y1 = line_coordinates[index][1]\n",
        "\n",
        "      if x0 is not None:\n",
        "        # Create Point instances for start and end coordinates\n",
        "        LINE_START = Point(int(x0), int(y0))\n",
        "        LINE_END = Point(int(x1), int(y1))\n",
        "\n",
        "\n",
        "      # Model prediction on single frame and conversion to supervision Detections\n",
        "      results = model(frame, verbose=False)[0]\n",
        "      detections = sv.Detections.from_ultralytics(results)\n",
        "      # Only consider class id from selected_classes defined above\n",
        "      detections = detections[np.isin(detections.class_id, selected_classes)]\n",
        "      # Only take the vehicles with certain confidance rate (in this case 0.5)\n",
        "      detections = detections[detections.confidence > 0.5]\n",
        "      # Tracking detections (Buradaki kodu da küçülttüm)\n",
        "      detections = byte_tracker.update_with_detections(detections)\n",
        "      overtaking(frame,detections)\n",
        "      redlight(frame=frame,current_light_state=frame_lights[index],y0=y0,detections=detections)\n",
        "      speed_detector(detections, vehicle_speed_detail_list, index+1)\n",
        "      print(f\"index:{index}\")\n",
        "      print(f\"red light violaters : {red_light_violators}\")\n",
        "      labels = [\n",
        "          f\"#{tracker_id} {model.model.names[class_id]} {confidence:0.2f}\"\n",
        "          for confidence, class_id, tracker_id\n",
        "          in zip(detections.confidence, detections.class_id, detections.tracker_id)\n",
        "      ]\n",
        "      annotated_frame=box_annotator.annotate(\n",
        "          scene=frame.copy(),\n",
        "          detections=detections,\n",
        "          labels=labels)\n",
        "\n",
        "      final_license_plates_dict = plate(frame,detections,annotated_frame)\n",
        "      whitecolor = (255, 255, 255)\n",
        "      # Specify color for drawing the line (assuming BGR color format)\n",
        "      pil_image = Image.fromarray(annotated_frame)\n",
        "      draw = ImageDraw.Draw(pil_image)\n",
        "      text_position1 = (0, 130)  # Adjust 30 pixels above the line\n",
        "      index_ = f'index - - > {index} '\n",
        "      draw.text(text_position1, index_ , fill=whitecolor)  # White text\n",
        "\n",
        "      text_position = (0, 30)  # Adjust 30 pixels above the line\n",
        "      draw.text(text_position, frame_lights[index], fill=whitecolor)  # White text\n",
        "\n",
        "      # Draw line on the annotated frame\n",
        "      annotated_frame = np.array(pil_image)\n",
        "      if x0 is not None:\n",
        "        draw_line(annotated_frame, LINE_START, LINE_END, color=Color(255, 0, 0), thickness=2)\n",
        "\n",
        "      return annotated_frame\n",
        "    except IndexError:\n",
        "        # If detections are empty or index is out of bounds, return the original frame\n",
        "        return frame\n",
        "  # Process the whole video\n",
        "  sv.process_video(\n",
        "      source_path = SOURCE_VIDEO_PATH,\n",
        "      target_path = TARGET_VIDEO_PATH,\n",
        "      # target path = mid_video_path\n",
        "      callback=callback\n",
        "  )\n",
        "  wb = Workbook()\n",
        "  sheet = wb.active\n",
        "  sheet.title = \"Violation\"\n",
        "  previous_tracker_ids_list = list(previous_tracker_ids)\n",
        "  for i in range(len(previous_tracker_ids_list)):\n",
        "    sheet[\"A1\"] = len(previous_tracker_ids_list)\n",
        "    sheet[f\"A{i + 2}\"] = f\"Car No {previous_tracker_ids_list[i]}\"\n",
        "    sheet[\"D1\"] = 'Overtaking Violation'\n",
        "    sheet[\"C1\"] ='Red Light Violation'\n",
        "    sheet[\"E1\"] = 'Speed Violation'\n",
        "    sheet[\"F1\"] = \"Detected Speed\"\n",
        "    sheet[\"G1\"] = \"Speed Detection Time\"\n",
        "    sheet[\"B1\"] = \"Plate\"\n",
        "    sheet[\"H1\"] = \"Vehicle Type\"\n",
        "    if previous_tracker_ids_list[i] in overtaking_vio_cars:\n",
        "      sheet[f\"D{i + 2}\"] = 'TRUE'\n",
        "    else:\n",
        "      sheet[f\"D{i + 2}\"] = 'FALSE'\n",
        "    if previous_tracker_ids_list[i] in red_light_violators:\n",
        "      sheet[f\"C{i + 2}\"] = 'TRUE'\n",
        "    else:\n",
        "      sheet[f\"C{i + 2}\"] = 'FALSE'\n",
        "\n",
        "    for vehicle_detail in vehicle_speed_detail_list:\n",
        "      if previous_tracker_ids_list[i] == int(vehicle_detail[\"vehicle_id\"]):\n",
        "        sheet[f\"E{i+2}\"] = vehicle_detail[\"speed_violation\"]\n",
        "        sheet[f\"F{i+2}\"] = vehicle_detail[\"vehicle_exact_speed\"]\n",
        "        sheet[f\"G{i+2}\"] = vehicle_detail[\"speed_detection_time\"]\n",
        "        sheet[f\"H{i+2}\"] = vehicle_detail[\"vehicle_type\"]\n",
        "\n",
        "    for id in finalized_lisence_plates.keys():\n",
        "      if previous_tracker_ids_list[i] == id:\n",
        "        sheet[f\"B{i+2}\"] = finalized_lisence_plates[id][\"plaka\"]\n",
        "\n",
        "    excel_name = target_excel_path\n",
        "    wb.save(excel_name)"
      ],
      "metadata": {
        "id": "Q1STFlTRI3GM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyrebase\n",
        "from firebase_admin import storage as archive  # storage variable will be used for\n",
        "from google.oauth2 import service_account\n",
        "from googleapiclient.discovery import build\n",
        "import firebase_admin\n",
        "from firebase_admin import storage\n",
        "from firebase_admin import credentials\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "# config variable includes the necessary information for the pyrebase\n",
        "# it is used for directly reaching the files in the firebase storage\n",
        "\n",
        "config = {\n",
        "    \"apiKey\": \"AIzaSyCj-tEY9I21Ckqdns4efJ2pSyS-hngVNsw\",\n",
        "    \"authDomain\": \"traffic-violation-app-98a1c.firebaseapp.com\",\n",
        "    \"databaseURL\": \"https://traffic-violation-app-98a1c-default-rtdb.firebaseio.com\",\n",
        "    \"projectId\": \"traffic-violation-app-98a1c\",\n",
        "    \"storageBucket\": \"traffic-violation-app-98a1c.appspot.com\",\n",
        "    \"appId\": \"1:114619964291:web:2d4af8eb6af215653bf4b6\",\n",
        "    \"serviceAccount\": \"/content/drive/MyDrive/traffic_violation_app/json/serviceAccountKey.json\"\n",
        "}\n",
        "\n",
        "firebase_storage_app = pyrebase.initialize_app(config)\n",
        "firebase_storage = firebase_storage_app.storage()\n",
        "\n",
        "# Initialize Firebase Admin SDK\n",
        "cred = credentials.Certificate('/content/drive/MyDrive/traffic_violation_app/json/serviceAccountKey.json')\n",
        "firebase_admin.initialize_app(cred, {\n",
        "    'storageBucket': 'traffic-violation-app-98a1c.appspot.com'  # Replace with your Firebase Storage bucket URL\n",
        "})\n",
        "\n",
        "# Initialize Firebase Storage client\n",
        "bucket = archive.bucket()\n",
        "\n",
        "# Google Drive API setup\n",
        "SCOPES = ['https://www.googleapis.com/auth/drive.file']\n",
        "SERVICE_ACCOUNT_FILE = '/content/drive/MyDrive/traffic_violation_app/json/credentials.json'\n",
        "creds = service_account.Credentials.from_service_account_file(\n",
        "    SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
        "drive_service = build('drive', 'v3', credentials=creds)"
      ],
      "metadata": {
        "id": "cSnuaeQmQYGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to upload video to Firebase Storage\n",
        "def upload_video_to_firebase(video_file_path, firebase_storage_path):\n",
        "    try:\n",
        "        print(\"Starting video upload \" + str(video_file_path))\n",
        "\n",
        "        bucket = storage.bucket()\n",
        "        blob = bucket.blob(firebase_storage_path)\n",
        "\n",
        "        # Upload the video file\n",
        "        blob.upload_from_filename(video_file_path)\n",
        "\n",
        "        print(\"Video uploaded to Firebase Storage successfully.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error uploading file: {e}\")\n",
        "\n",
        "def check_storage():\n",
        "    file_names_raw = []\n",
        "    blobs = bucket.list_blobs()\n",
        "    for blob in blobs:\n",
        "        file_names_raw.append(blob.name)\n",
        "    file_names = [str(i) for i in file_names_raw if not i.endswith(\"/\") and \"Result_\" not in i]\n",
        "    return file_names\n",
        "\n",
        "\n",
        "def check_new_files(previous_files):\n",
        "    all_files = check_storage()\n",
        "    new_files = list(set(all_files) - set(previous_files))\n",
        "    if new_files:\n",
        "        print(f\"{new_files} are added\")\n",
        "    return new_files\n",
        "\n",
        "\n",
        "def download_new_files(new_files):\n",
        "    downloaded_files = []\n",
        "    raw_path = \"/content/drive/MyDrive/traffic_violation_app/rawData/\"\n",
        "    processed_path = \"/content/drive/MyDrive/traffic_violation_app/processedData/\"\n",
        "    for file_directory in new_files:\n",
        "        #if file_directory.endswith(\".mp4\"):\n",
        "        file_name = os.path.basename(file_directory)\n",
        "        print(f\"Downloading {file_name} to the local computer\")\n",
        "        cloudfilename = file_directory\n",
        "        localfilename = raw_path + file_name\n",
        "        firebase_storage.child().download(cloudfilename, localfilename)\n",
        "        print(f\"{file_name} is downloaded to rawData\")\n",
        "        file_info = {\n",
        "            \"database_directory\": os.path.dirname(file_directory),\n",
        "            \"file_name\": file_name,\n",
        "            \"local_directory\": raw_path + file_name,\n",
        "            \"processed_directory_video\": processed_path + \"Result_\" + file_name.replace(\".mp4\",\".mov\"),\n",
        "            \"new_database_directory_video\": os.path.dirname(file_directory) + \"/Result_\" + file_name,\n",
        "            \"processed_directory_excel\": processed_path + file_name.replace(\".mp4\", \".xlsx\"),\n",
        "            \"new_database_directory_excel\": os.path.dirname(file_directory) + file_name.replace(\".mp4\", \".xlsx\")\n",
        "       }\n",
        "        downloaded_files.append(file_info)\n",
        "    return downloaded_files\n",
        "\n",
        "\n",
        "\n",
        "def process_data(downloaded_files):\n",
        "    processed_files = []\n",
        "    for file_info in downloaded_files:\n",
        "        if file_info[\"file_name\"].endswith(\".mp4\"):\n",
        "            print(f\"Processing {file_info['file_name']}\")\n",
        "            source_video_file = file_info[\"local_directory\"]\n",
        "            source_excel_file = file_info[\"local_directory\"].replace(\".mp4\", \".xlsx\")\n",
        "            image_process(source_video_file, source_excel_file)\n",
        "            processed_files.append(file_info)\n",
        "            print(f\"{file_info['file_name']} is succesfully processed.\")\n",
        "            # excel_results = process_excel(new_excel_path)\n",
        "    return processed_files\n",
        "\n",
        "\n",
        "def upload_processed_file(processed_files):\n",
        "    for file_info in processed_files:\n",
        "        upload_video_to_firebase(file_info['processed_directory_video'], file_info['new_database_directory_video'])\n",
        "        print(f\"{file_info['file_name']} is successfully uploaded\")\n",
        "        try:\n",
        "          upload_video_to_firebase(file_info['processed_directory_excel'], file_info['new_database_directory_excel'])\n",
        "          print(f\"{os.path.basename(file_info['processed_directory_excel'])} is successfully uploaded\")\n",
        "        except Exception as e:\n",
        "          print(f\"Error uploading excel: {e}\")"
      ],
      "metadata": {
        "id": "vU_p1LVcSrOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start Server\n",
        "\n",
        "import time\n",
        "\n",
        "print(check_storage())\n",
        "\n",
        "while True:\n",
        "\n",
        "    files = check_storage()\n",
        "    time.sleep(10)\n",
        "    new_files = check_new_files(files)\n",
        "    downloaded_files = download_new_files(new_files)\n",
        "    processed_files = process_data(downloaded_files)\n",
        "    upload_processed_file(processed_files)"
      ],
      "metadata": {
        "id": "ye1c0KcBS1AK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}